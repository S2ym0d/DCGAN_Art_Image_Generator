{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqTfMxYMV1Vn"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYPgb1YdV0J7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download data\n"
      ],
      "metadata": {
        "id": "vfXdjoGLYcFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown #google drive file id"
      ],
      "metadata": {
        "id": "_gyduAUjYeVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/images.zip\" -d \"../\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "XK0GLpjBZVhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf /content/images"
      ],
      "metadata": {
        "id": "Tvb8ZMTbZfkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/images\""
      ],
      "metadata": {
        "id": "Vv5naJX9aRWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare data\n"
      ],
      "metadata": {
        "id": "OdCc3nRLZ9-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([0.5], [0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "sV6L_SURZ_ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageFolder(root=data_folder, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "q3eIpDzZaZb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check data"
      ],
      "metadata": {
        "id": "5qdGWqkpakcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "  img = img / 2 + 0.5\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "dataiter = iter(dataloader)\n",
        "images, _ = next(dataiter)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images[:16], nrow=4))"
      ],
      "metadata": {
        "id": "L6kiUn-xamH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DCGAN setup"
      ],
      "metadata": {
        "id": "jLCOTiQ8bMmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "f0yvZmwgbP27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv') != -1:\n",
        "    nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "  elif classname.find('BatchNorm') != -1:\n",
        "    nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "    nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "kzItEDE4bxL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generator"
      ],
      "metadata": {
        "id": "QVsWe9LGb1GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, nz, ngf, nc):\n",
        "    super(Generator, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "      nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "      nn.BatchNorm2d(ngf * 8),\n",
        "      nn.ReLU(True),\n",
        "\n",
        "      nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ngf * 4),\n",
        "      nn.ReLU(True),\n",
        "\n",
        "      nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ngf * 2),\n",
        "      nn.ReLU(True),\n",
        "\n",
        "      nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ngf),\n",
        "      nn.ReLU(True),\n",
        "\n",
        "      nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "      nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.main(input)"
      ],
      "metadata": {
        "id": "NfV7_c_Fb2bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Discriminator"
      ],
      "metadata": {
        "id": "W8Ph3RoZeU72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, nc, ndf):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "      nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "      nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ndf * 2),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "      nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ndf * 4),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "      nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ndf * 8),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "      nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.main(input)"
      ],
      "metadata": {
        "id": "ikZaexS3eW_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameters and models initialization"
      ],
      "metadata": {
        "id": "rkMyLmupejUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nz = 100     # Latent vector size\n",
        "ngf = 64     # Generator feature map size\n",
        "ndf = 64     # Discriminator feature map size\n",
        "nc = 3       # Number of channels\n",
        "\n",
        "netG = Generator(nz, ngf, nc).to(device)\n",
        "netG.apply(weights_init)\n",
        "\n",
        "netD = Discriminator(nc, ndf).to(device)\n",
        "netD.apply(weights_init)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VPb8zBr8engk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "78qYGG4wgu8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training setup"
      ],
      "metadata": {
        "id": "nlUojtVKhg9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "6H4JE2Qggxo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "num_epochs = 30\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "P0FxUwjqhNsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training loop"
      ],
      "metadata": {
        "id": "bFmNODhBhjlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, data in enumerate(dataloader):\n",
        "    # Update Discriminator\n",
        "\n",
        "    netD.zero_grad()\n",
        "\n",
        "    # Real\n",
        "    real_images = data[0].to(device)\n",
        "    batch_size = real_images.size(0)\n",
        "    real_labels = torch.ones(batch_size, device=device)\n",
        "    output = netD(real_images).view(-1)\n",
        "    lossD_real = loss_fn(output, real_labels)\n",
        "\n",
        "    # Fake\n",
        "    noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "    fake_images = netG(noise)\n",
        "    fake_labels = torch.zeros(batch_size, device=device)\n",
        "    output = netD(fake_images.detach()).view(-1)\n",
        "    lossD_fake = loss_fn(output, fake_labels)\n",
        "\n",
        "    # Total loss\n",
        "    lossD = lossD_real + lossD_fake\n",
        "    lossD.backward()\n",
        "    optimizerD.step()\n",
        "\n",
        "    # Update Generator\n",
        "\n",
        "    netG.zero_grad()\n",
        "    output = netD(fake_images).view(-1)\n",
        "    lossG = loss_fn(output, real_labels)\n",
        "    lossG.backward()\n",
        "    optimizerG.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      print(f\"[{epoch}/{num_epochs}][{i}/{len(dataloader)}] \"\n",
        "        f\"Loss_D: {lossD.item():.4f} Loss_G: {lossG.item():.4f}\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    fake = netG(fixed_noise).detach().cpu()\n",
        "  img_grid = vutils.make_grid(fake, padding=2, normalize=True)\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(np.transpose(img_grid, (1, 2, 0)))\n",
        "  plt.show()\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    torch.save(netG.state_dict(), f\"generator_epoch_{epoch+1}.pth\")\n",
        "    torch.save(netD.state_dict(), f\"discriminator_epoch_{epoch+1}.pth\")"
      ],
      "metadata": {
        "id": "yw0YEhyEhlxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(netG.state_dict(), f\"generator.pth\")\n",
        "torch.save(netD.state_dict(), f\"discriminator.pth\")"
      ],
      "metadata": {
        "id": "wpzWAyBjnFCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tests"
      ],
      "metadata": {
        "id": "KA77qQ7CMB8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netG = Generator(nz, ngf, nc).to(device)\n",
        "netG.load_state_dict(torch.load(\"generator.pth\", map_location=device))\n",
        "netG.eval()"
      ],
      "metadata": {
        "id": "aHZtJiftN_mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real vs Fake comparison"
      ],
      "metadata": {
        "id": "mxuAS6PJMvVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(dataloader)\n",
        "real_images, _ = next(dataiter)\n",
        "real_images = real_images[:64].to(device)"
      ],
      "metadata": {
        "id": "I_LaxtV3Mnww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "with torch.no_grad():\n",
        "    fake_images = netG(noise).detach().cpu()"
      ],
      "metadata": {
        "id": "KaMKTNvtMuon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_images_cpu = real_images.cpu() * 0.5 + 0.5\n",
        "fake_images = fake_images * 0.5 + 0.5"
      ],
      "metadata": {
        "id": "lBTTC8RSMw_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_real = torchvision.utils.make_grid(real_images_cpu, nrow=8, padding=2)\n",
        "grid_fake = torchvision.utils.make_grid(fake_images, nrow=8, padding=2)"
      ],
      "metadata": {
        "id": "DlWpbkELMzH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "axes[0].imshow(np.transpose(grid_real.numpy(), (1, 2, 0)))\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title(\"Real Images\")\n",
        "\n",
        "axes[1].imshow(np.transpose(grid_fake.numpy(), (1, 2, 0)))\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title(\"Fake Images\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KJl0wfqxM01K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latent cycle gif"
      ],
      "metadata": {
        "id": "32Z28DiUNz0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio"
      ],
      "metadata": {
        "id": "smbXumdMORK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z1 = torch.randn(nz, device=device)\n",
        "z1_unit = z1\n",
        "\n",
        "z2 = torch.randn(nz, device=device)\n",
        "#z2 = z2 - (z2 @ z1_unit) * z1_unit\n",
        "z2_unit = z2"
      ],
      "metadata": {
        "id": "rA-T-n6LN2GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_frames = 60\n",
        "frames = []\n",
        "for i in range(num_frames):\n",
        "    theta = 2 * np.pi * i / num_frames\n",
        "\n",
        "    z_interp = (z1_unit * np.cos(theta) + z2_unit * np.sin(theta)).unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
        "    with torch.no_grad():\n",
        "        fake_img = netG(z_interp).cpu().squeeze(0)\n",
        "\n",
        "    img = (fake_img * 0.5 + 0.5).permute(1, 2, 0).numpy()  # H×W×C, float in [0,1]\n",
        "    img_uint8 = (img * 255).astype(np.uint8)\n",
        "    frames.append(img_uint8)"
      ],
      "metadata": {
        "id": "qd8bPvIxOHEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gif_path = \"latent_circle.gif\"\n",
        "imageio.mimsave(gif_path, frames, fps=10, loop=0)"
      ],
      "metadata": {
        "id": "7p9lhNEZONP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image\n",
        "display(Image(filename=\"latent_circle.gif\"))"
      ],
      "metadata": {
        "id": "T85Y1V1_PpAh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}